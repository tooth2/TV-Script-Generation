# TV-Script-Generation
Recurrent networks to generate new text from TV scripts; LSTM(long short-term memory) networks with PyTorch.
## Background 
* RNN , Recurrent Neural Networks (RNNs), which are machine learning models that are able to recognize and act on sequences of inputs.
* LSTM: Long Short-Term Memory Networks (LSTM), which forms a memory about a sequence of inputs, over time.

## Implementation Approach
### RNN & LSTM Implementation 
Train recurrent neural networks to generate new characters,words, and bodies of text.

### Embeddings & Tockenization/Punctuation processing 
 embeddings in neural networks by implementing a word2vec model that converts words into a representative vector of numerical values.
### Hyperparameters Tuning 
* number of different hyperparameters that are important for the model such as learning rates.
* tuning each hyperparameter approach

